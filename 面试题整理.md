---

typora-copy-images-to: img
typora-root-url: img
---

[TOC]



# SEATA

1. seata 回滚，支持指定回滚异常类



事务开启流程

​	1。 启动时创建globalscanner , scanner中实现后置启方法 **beanpostprocessor** ，后置方法内创建带有 @globaltransactional 注解的代理类。 定义 **globaltransactionalInterceptor** 

​	2。 **globaltransactionalInterceptor** 内，执行全局事务方法时，

```java
 // 1. 创建一个DefaultGlobalTransaction类
        GlobalTransaction tx = GlobalTransactionContext.getCurrentOrCreate();

        // 1.1 获取基本信息，包含 回滚规则
        TransactionInfo txInfo = business.getTransactionInfo();
        if (txInfo == null) {
            throw new ShouldNeverHappenException("transactionInfo does not exist");
        }
        try {

            // 2. begin transaction
            //开启事务，发起请求，通知协调中心，事务开启，并获取返回的全局事务id
            beginTransaction(txInfo, tx);

            Object rs = null;
            try {

                // Do Your Business
                rs = business.execute();

            } catch (Throwable ex) {

                // 3.the needed business exception to rollback.
               //回滚满足 定义的规则，否则事务提交
                completeTransactionAfterThrowing(txInfo,tx,ex);
                throw ex;
            }

            // 4. everything is fine, commit.
            commitTransaction(tx);

            return rs;
        } finally {
            //5. clear
            triggerAfterCompletion();
            cleanUp();
        }
```

3。 GlobalScanner类初始化的时候，初始化了RM TM客户端。netty客户端，用于连接协调中心。

# 常见算法面试

#### 二分查找

```
/**
     * 循环实现二分查找
     *
     * @param array
     * @param key
     * @return
     */
    public static int binarySort(int[] array, int key) {
        int low = 0;
        int high = array.length - 1;
        while (low <= high) {
            int mid = (low + high) >>> 1;
            if (key < array[mid]) {
                high = mid - 1;
            } else if (key > array[mid]) {
                low = mid + 1;
            } else {
                return mid;
            }
        }
        return -1;
    }

    /**
     * 递归实现二分查找
     *
     * @param array
     * @param key
     * @param low
     * @param high
     * @return
     */
    public static int binarySortRecursion(int[] array, int key, int low, int high) {
        if (low <= high) {
            int mid = (low + high) >>> 1;
            if (key < array[mid]) {
                return binarySortRecursion(array, key, low, mid - 1);
            } else if (key > array[mid]) {
                return binarySortRecursion(array, key, mid + 1, high);
            } else {
                return mid;
            }
        }
        return -1;
    }
```



# 数据结构

#### 红黑树

1.每个节点非红即黑；

2.根节点总是黑色的；

3.、每个叶子节点都是黑色的空节点（NIL节点）；

4.如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；

5.从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）

# 并发编程

#### JAVA内存模型 JMM

![img](https://upload-images.jianshu.io/upload_images/4899162-66736384361f6b8b.png?imageMogr2/auto-orient/strip|imageView2/2/w/812/format/webp)

- **工作内存与主内存交互**

  ​	物理机高速缓存和主内存之间的交互有协议，同样的，java内存中线程的工作内存和主内存的交互是由java虚拟机定义了如下的8种操作来完成的，每种操作必须是原子性的(double和long类型在某些平台有例外，参考[volatile详解和非原子性协定](##volatile修饰的变量的特殊规则))
  ​     java虚拟机中主内存和工作内存交互，就是一个变量如何从主内存传输到工作内存中，如何把修改后的变量从工作内存同步回主内存。

  > **lock(锁定)**:作用于主内存的变量，一个变量在同一时间只能一个线程锁定，该操作表示这条线成独占这个变量
  >
  > **unlock(解锁)**:作用于主内存的变量，表示这个变量的状态由处于锁定状态被释放，这样其他线程才能对该变量进行锁定
  >
  > **read(读取)**:作用于主内存变量，表示把一个主内存变量的值传输到线程的工作内存，以便随后的load操作使用
  >
  > **load(载入)**:作用于线程的工作内存的变量，表示把read操作从主内存中读取的变量的值放到工作内存的变量副本中(副本是相对于主内存的变量而言的)
  >
  > **use(使用)**:作用于线程的工作内存中的变量，表示把工作内存中的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时就会执行该操作
  >
  > **assign(赋值)**:作用于线程的工作内存的变量，表示把执行引擎返回的结果赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的字节码指令时就会执行该操作
  >
  > **store(存储)**:作用于线程的工作内存中的变量，把工作内存中的一个变量的值传递给主内存，以便随后的write操作使用
  >
  > **write(写入)**:作用于主内存的变量，把store操作从工作内存中得到的变量的值放入主内存的变量中

  对于这几步操作有一定的规则，并且运行是有可能会对这些指令进行重新排序执行，前提是在不影响执行结果。

  > **不允许read和load、store和write操作之一单独出现**，也就是不允许从主内存读取了变量的值但是工作内存不接收的情况，或者不允许从工作内存将变量的值回写到主内存但是主内存不接收的情况
  >
  > **不允许一个线程丢弃最近的assign操作**，也就是不允许线程在自己的工作线程中修改了变量的值却不同步/回写到主内存
  >
  > **不允许一个线程回写没有修改的变量到主内存**，也就是如果线程工作内存中变量没有发生过任何assign操作，是不允许将该变量的值回写到主内存
  >
  > **变量只能在主内存中产生**，不允许在工作内存中直接使用一个未被初始化的变量，也就是没有执行load或者assign操作。也就是说在执行use、store之前必须对相同的变量执行了load、assign操作
  >
  > **一个变量在同一时刻只能被一个线程对其进行lock操作**，也就是说一个线程一旦对一个变量加锁后，在该线程没有释放掉锁之前，其他线程是不能对其加锁的，但是同一个线程对一个变量加锁后，可以继续加锁，同时在释放锁的时候释放锁次数必须和加锁次数相同。
  >
  > **对变量执行lock操作，就会清空工作空间该变量的值**，执行引擎使用这个变量之前，需要重新load或者assign操作初始化变量的值
  >
  > **不允许对没有lock的变量执行unlock操作**，如果一个变量没有被lock操作，那也不能对其执行unlock操作，当然一个线程也不能对被其他线程lock的变量执行unlock操作
  >
  > **对一个变量执行unlock之前，必须先把变量同步回主内存中**，也就是执行store和write操作
  >
  > 

- volatile**修饰的变量的特殊规则**

  volatile修饰变量以后，1. 以上动作中，得确保线程中的变量，是不会改变的。并且，当前变量修改值以后，得将结果输出到主内存中（use和load 被绑定 其他线程无法打断，成原子操作， assign和store绑定），这样保证了变量在各个线程中的值是一样。2. 指令不会进行重排。

- **long 和 double 变量的特殊规则**

  long和double长度64位，存储占两行。操作不是原子的，

#### AQS

​	AQS内维护了一个信号量state，使用volatile修饰。还有一个CLH队列。

​	AQS有两种锁，独占锁ReentrantLock，共享锁Semaphore/CountDownLatch。



#### Synchronized和ReentrantLock

- 两者都是可重入锁

- Synchronized依赖于jvm而ReentrantLock依赖于API

  synchronized在jdk1.6之后进行了优化， 有了一个锁升级的概念。在对象的MarkWord属性，中有几个标记位，来说明当前对象的锁是什么类型的。进行一系列锁竞争之后，对象的锁从无锁---》偏向锁---》轻量锁----》重量锁。

  1. ​	偏向锁：当前资源，只有一个线程执行，并未产生竞争，则当前的锁为偏向锁，，锁偏向于当前线程，并在markword中进行标记。
  2. ​    轻量锁：并发执行时，线程栈中存在一块区域叫lockrecord，两个线程谁竞争成功，就将对象的markword修改  指针指向线程栈中的lockrecord。
  3. ​     重量级锁： 轻量级锁的情况下，再次发生竞争，则锁变成重量级锁，markword中的值指向对象monitor

- ReentrantLock有一些高级功能：a. 等待中可中断；b. 可实现公平锁 c. 可实现选择性通知

#### 分布式锁

- 可用mysql。  基于版本号，或者排它锁，等等。 数据库开销大。
- redis。 设置key 超时时间，考虑删除key。还要考虑key别在执行过程中过期。
- 使用redission

#### 线程

- 线程的状态

  ```java
  public enum State {
      //线程刚创建
      NEW, 
      //在JVM中正在运行的线程
      RUNNABLE ，
      //线程处于阻塞状态，等待监视锁，可以重新进行同步代码块中执行
      BLOCKED,
      //等待状态
      WAITING,
      //调用sleep() join() wait()方法可能导致线程处于等待状态
      TIMED_WAITING,
      //线程执行完毕，已经退出
      TERMINATED;
  }
  ```

- 线程的方法说明

  - Sleep() : 当前线程休眠，状态改为阻塞状态，不释放锁。
  - join(): 线程调用join方法，则当前线程强制执行，其他线程进入阻塞。可以被interrupt打断
  - setPriority(): 设置线程优先级，越大调用优先级的概率越高。
  - isAlive():判断线程是否执行
  - yield():  当前线程阻塞，其他线程先执行。
  - interrupt（）：线程中断。
  - wait(): 线程等待，进入阻塞状态。 在同步块内才能执行
  - notify(): 唤醒当前线程，进入运行状态。
  - notifyAll():唤醒所有的线程。

#### 线程池

- 线程池创建时的参数说明

  > coresize：线程池长存在的线程数
  >
  > MaxSize：线程池中最大可运行的线程数
  >
  > time：		线程池中超过coresize的那些线程的 空闲最长时间，超过则销毁
  >
  > timeunit： 时间单位
  >
  > queue：	超过maxsize的线程，对到改队列中。



#### Future&Fork/Join





# 设计模式

## 软件开发6大原则

- 开闭原则：对扩展开发，对修改关闭。程序扩展时尽可能的别修改原代码。
- 里氏替换原则：任何基类可以出现的地方，子类一定可以出现
- 依赖倒置原则：针对接口编程，依赖抽象，不依赖具体。
- 迪米特法则（最少知道原则）：一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立
- 合成复用原则：组合/聚合复用原则（Composition/Aggregate Reuse Principle，CARP）。它要求在软件复用时，要尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现

#### 代理

- **动态代理**

  jdk动态代理和cglib动态代理。

  两者实现方式不同。
  
  1。 jdk
  
  ```java
  public class ProxyFactory{
      //维护一个目标对象
      private Object target;
      public ProxyFactory(Object target){
          this.target=target;
      }
     //给目标对象生成代理对象
      public Object getProxyInstance(){
          return Proxy.newProxyInstance(
                  target.getClass().getClassLoader(),
                  target.getClass().getInterfaces(),
                  new InvocationHandler() {
                      @Override
                      public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                          System.out.println("开始事务2");
                          //执行目标对象方法
                          Object returnValue = method.invoke(target, args);
                          System.out.println("提交事务2");
                          return returnValue;
                      }
                  }
          );
      }
  }
  ```
  
  
  
  2。cglib
  
  ```java
  /**
   * Cglib子类代理工厂
   * 对UserDao在内存中动态构建一个子类对象
   */
  public class ProxyFactory implements MethodInterceptor{
      //维护目标对象
      private Object target;
  
      public ProxyFactory(Object target) {
          this.target = target;
      }
  
      //给目标对象创建一个代理对象
      public Object getProxyInstance(){
          //1.工具类
          Enhancer en = new Enhancer();
          //2.设置父类
          en.setSuperclass(target.getClass());
          //3.设置回调函数
          en.setCallback(this);
          //4.创建子类(代理对象)
          return en.create();
  
      }
  
      @Override
      public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
          System.out.println("开始事务...");
  
          //执行目标对象的方法
          Object returnValue = method.invoke(target, args);
  
          System.out.println("提交事务...");
  
          return returnValue;
      }
  }
  ```
  
  

# Spring

#### AOP

@EnableAspectJAutoProxy   ----> import AspectJAutoProxyRegistrar.class ---->  向容器中注册了 AnnotationAwareAspectJAutoProxyCreator.class 实现了 BeanPostProcessor

#### Bean

bean配置的几种方式。 xml，@bean，

# Mysql

#### 事务

1. **特性**:

 -	**原子性：**一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样
 -	**一致性：**在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。
 -	**隔离性：**数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）
 -	**持久性：**事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

2. **事务并发出现的问题**

-	**脏读**：读取了其他事务未执行完的数据。比如B读取了A执行的结果，但是A回滚。
-	**不可重复度**: 事务A读取了一条记录，当事务B将结果修改以后，事务A再次读取的时候，数据变成事务B执行的结果，对于事务A来说，两次读取的结果不同，所以称为不可重复读。
-	**幻读**: 事务A将满足条件的数据进行了更新操作，但是事务B此时执行了insert操作，事务A结果查询发现多了一条未执行的记录。成为幻读。

3. **隔离级别**

- **读未提交**: 
- **读已提交**:
- **可重复读：**
- **串行化：**





#### Explain

​	**列说明**

 -  id列： 执行顺序编号，越大执行优先级越高，id为null最后执行
 -  select_type:      1) simple: 简单查询。   2）primary：复杂查询中 最外层的select 3）subquery：select中的子查询（不在from子句中） 4）derived：包含在from子句中的子查询。mysql会将结果存放在临时表中，派生表。 5）union：在union中的第二个和虽有的select
-  table列：
-  type列： System》const》eq_ref》ref》range》index》all，执行效率排序。
   -  System和const，一般为以 主键和unique索引作为条件查询，并且只能查出一条街结果的情况下。
   -  eq_ref：多变关联查询，primarykey和unique key 作为关联条件ref
   -  ref：不是唯一索引，作为条件
   -  range：使用索引进行范围查询
   -  index：扫描全表的索引，比ALL快
   -  ALL：全表扫描
-  possible_key： 可能使用了哪个索引
-  key：
-  key_len列：  计算规则      char(n): n字节长度； varchar(n): 2字节存储字符串长度，如果是utf-8，长度为3n+2，；tinyint：1 smallint：2， int：4，bigint：8；date：3，timestamp：4，datetime：8
-  rows列：估计要读取并检索的行数
-  extra列：

**最左前缀法则**

如果索引了多列，要最受最左前缀法则，指的是查询从索引的最左前列开始并不跳过索引中的列。

**别在索引裂伤做任何操作（计算、函数、类型转换）**

**存储索引不能使用索引中范围条件右边的列**

**尽量使用覆盖索引**：只查询索引中的值

**mysql在使用不等于的时候无法使用索引**

**isnull，notnull无法使用索引**

**like 'xxxx%'**可以走索引

**mysql内有优化器，**执行前回评估走索引是否值得，如果一个范围查询，查询出的结果很多，这就没必要走索引了，查询索引，然后再查表，更浪费时间

# java基础



## 集合

- #### ArrayList和LinkedList的不同

  - 都是线程不安全的
  - Arraylist底层是数组，查询复杂度为O(1)，LinkedList底层是双向链表，查询复杂度为O(n)；
  - 插入：ArrayList是O(n-1)， linkedlist是O(1)
  - Arraylist的默认长度是10，当插入数据长度超过原先的数组长度，数组长度扩容1/2，并把原先的值copy到新的数组中；LinkedList空间浪费在每个元素的指针上；

- **List的排序**

  - Collection.sort(list) 正序；Collection.reverse(list) 倒序；Collections.sort(list, comparator())
  
- **ConcurrentHashMap 1.7 和 1.8的区别**

  - 1.7

    - 数据结构是，**实例化时初始化的**Segment+HashEntry结构，防并发的措施是 segment extends **ReentrantLock**,同一个segment上同步，不同segment上可并发执行。put过程中，segment.trylock，锁成功，执行put操作，如果锁失败，scanAndLockForPut，单核处理器重试一次锁，多核的重试64次。
    - 因为`ConcurrentHashMap`是可以并发插入数据的，所以在准确计算元素时存在一定的难度，一般的思路是统计每个`Segment`对象中的元素个数，然后进行累加，但是这种方式计算出来的结果并不一样的准确的，因为在计算后面几个`Segment`的元素个数时，已经计算过的`Segment`同时可能有数据的插入或则删除，先采用不加锁的方式，连续计算元素的个数，最多计算3次：1、如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；2、如果前后两次计算结果都不同，则给每个`Segment`进行加锁，再计算一次元素的个数；

  - **1.8**

    - 数据结构，Node+Cas+Sychronized，并且在执行**第一次put的时候初始化**的node数据组

      ```
      private final Node<K,V>[] initTable() { 
          Node<K,V>[] tab; int sc;
          while ((tab = table) == null || tab.length == 0) {
          	//其他线程如果在初始化过程中，sizeCtl = -1,线程暂停，让其他线程先执行。
              if ((sc = sizeCtl) < 0)
                  Thread.yield(); // lost initialization race; just spin
              else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { //cas将sizectl = -1
                  try {
                      if ((tab = table) == null || tab.length == 0) { 
                          int n = (sc > 0) ? sc : DEFAULT_CAPACITY; 
                          @SuppressWarnings("unchecked") 
                          Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                          table = tab = nt; 
                          sc = n - (n >>> 2); 
                      } 
                  } finally { 
                      sizeCtl = sc;
                  }
                  break; 
              } 
          }
           return tab;
      }
      ```

      

## NIO

- **NIO，select/epoll的区别，多路复用的原理**

# Kafka

为什么要对Topic下数据进行分区存储？

 1、commit log文件会受到所在机器的文件系统大小的限制，分区之后，理论上一个topic可以处理任意数量的数据。 2、为了提高并行度。

**消费组**概念

> 每个消费者，可以指定自己所在的消费组（自定义），如果多个消费者所在的消费组一样，那消息只能被这个组内的一个消费者消费。此模式相当于是 **队列模式**
>
> **不同的消费组**只会有一个消费者能消费的消息，可以作为 **订阅发布模式**

**消费位置**

- 信息消费，可以在消费者启动时，将 **所有的消息从头开始消费**（kafka消费 **偏移量** **消费者**自己维护）
- 也可以指定在 **partition** 中的某个位置开始消费

**server.properties**

- broker.id   0 每个broker的唯一id
- log.dirs      日志路径
- listeners   9092      监听的端口
- zookeeper.connect        
- **log.retension.hours** 消息日志报文时间
- **min.insync.replicas** 1  生产者等到kafka的消息备份的数量超过1的时候，才会继续进行其他的操作，不然会抛错。
- delete.topic.enable false

**常用命令**

```shell
#启动命令
bin/kafka-server-start.sh -daemon config/server.properties
#创建主题
bin/kafka-topics.sh --create --zookeeper 192.168.0.60:2181 --replication-factor 1 --partitions 1 --topic test
##查看主题列表
bin/kafka-topics.sh --list --zookeeper 192.168.0.60:2181
##删除主题
bin/kafka-topics.sh --delete --topic test --zookeeper 192.168.0.60:2181

#生成消息
bin/kafka-console-producer.sh --broker-list 192.168.0.60:9092 --topic test 

#消费消息，如果想要从topic的开头开始消费，加参数 --from-beginning
bin/kafka-console-consumer.sh --bootstrap-server 192.168.0.60:9092  --consumer-property group.id=testGroup --topic test 





```

#查看某个消费组的偏移量
`bin/kafka‐consumer‐groups.sh ‐‐bootstrap‐server 192.168.0.60:9092 ‐‐describe ‐‐group testGroup`

![image-20200429195835987](/image-20200429195835987.png)

#查看topic
`bin/kafka-topics.sh --describe --zookeeper 127.0.0.1:2181 --topic test`

![image-20200429201318476](/image-20200429201318476.png)



**Kafka拓扑结构**

![image-20200330220411227](/image-20200330220411227.png)

**kafka核心总控制器**

![image-20200330220546478](/image-20200330220546478.png)

​	**Controller的选举机制**  kafka每个实例启动的时候都会想 zk 写入一个节点数据，/controller ，谁写成功，谁就做为controller；controller为临时节点，当controller对应的节点挂掉以后，/controller临时节点会自动消失，其他的实例watch到节点消失，则都会进行写/controller，还是谁写成功，谁作为controller。

**Partition副本选举机制**

![image-20200330221552425](/image-20200330221552425.png)

**Rebanlance选举策略**

![image-20200331092826937](/image-20200331092826937.png)

#### 线上问题及优化

1. **消失丢失情况**

   ![image-20200331112619963](/image-20200331112619963.png)

2. **消息重复消费**

   ![image-20200331112925452](/image-20200331112925452.png)

3. **消息乱序**

   ![image-20200331113129676](/image-20200331113129676.png)

4. **消息挤压**

   ![image-20200331113644943](/image-20200331113644943.png)

# Redis

#### redis持久化机制

1. **AOF**

   将每条写命令作为日志，以append-only模式写入一个日志文件，在Redis重启时，通过回放日志中的写入指令来重构整个数据。

   如果同时使用RDB和AOF两种持久化机制，那么在Redis重启时，**会使用AOF来重新构建数据，因为AOF中的数据更加完整!**

2. **RDB**

   - 优点：RDB会生成多个数据文件，每个数据文件代表了某一时刻的Redis的数据，适合做冷备，将完整的数据文件可以发送给其他机器; 2. RDB对redis的影像比较小，redis  fork一个子进程来进行RDB
   - 缺点：没有AOF保存的数据完整；如果数据比较大，产生文件时可能会阻塞进程。

#### 三种模式

**1、redis-cluster**

A、采用去中心化的思想，没有中心节点的说法，它使用hash slot方式将16348个hash slot覆盖到所有节点上，对于存储的每个key值，使用CRC16（KEY）&16348=slot得到他对应的hash slot，

并在访问key的时候就去找他的hash slot在哪一个节点上，然后由当前访问节点从实际被分配了这个hash slot的节点去取数据，节点之间使用轻量协议通信 减少带宽占用 性能很高，

自动实现负载均衡与高可用，自动实现failover并且支持动态扩展。

B、其内部中也需要配置主从，并且内部也是采用哨兵模式，如果有半数节点发现某个异常节点，共同决定更改异常节点的状态，如果改节点是主节点，则对应的从节点自动顶替为主节点，当原先的主节点上线后，则会变为从节点。

**如果集群中的master没有slave节点，则master挂掉后整个集群就会进入fail状态，因为集群的slot映射不完整。如果集群超过半数以上的master挂掉，无论是否有slave，集群都会进入fail状态。**

C、根据官方推荐 集群部署至少要3台以上的master节点。

2、**主从复制**

![img](/1350922-20191006113541904-1736285180.png)

- 从数据库连接主数据库，发送SYNC命令； 
- 主数据库接收到SYNC命令后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； 
- 主数据库BGSAVE执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令； 
- 从数据库收到快照文件后丢弃所有旧数据，载入收到的快照； 
- 主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令； 
- 从数据库完成对快照的载入，开始接收命令请求，并执行来自主数据库缓冲区的写命令；（**从数据库初始化完成**）
- 主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令（**从数据库初始化完成后的操作**）
- 出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库，增量复制。
- 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。

**优点**：

- 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离；
- 为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成；
- Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力；
- Master Server是以非阻塞的方式为Slaves提供服务。所以在Master-Slave同步期间，客户端仍然可以提交查询或修改请求；
- Slave Server同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据；

**缺点**

- Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复；
- 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；
- 如果多个Slave断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要Slave启动，就会发送sync请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO剧增从而宕机。
- Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；

**3、哨兵模式**

- 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器；
- 当哨兵监测到master宕机，会自动将slave切换成master，然后通过**发布订阅模式**通知其他的从服务器，修改配置文件，让它们切换主机；

![img](/1350922-20191006122611921-809764078.png)

**故障切换的过程：**

　　假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为**主观下线**。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为**客观下线**。这样对于客户端而言，一切都是透明的。

**哨兵模式的工作方式：**

- 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。
- 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）
- 如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态
- 当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）
- 在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。
- 当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
- 若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。

#### 单线程为什么那么快

- 内存中操作
- 单线程，减少线程切换
- 多路io复用：**可以同时监控多个网络连接**

### key的淘汰策略

- noeviction: 不删除策略, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。 大多数写命令都会导致占用更多的内存(有极少数会例外, 如 DEL )。
- allkeys-lru: 所有key通用; 优先删除最近最少使用(less recently used ,LRU) 的 key。
- volatile-lru: 只限于设置了 expire 的部分; 优先删除最近最少使用(less recently used ,LRU) 的 key。
- allkeys-random: 所有key通用; 随机删除一部分 key。
- volatile-random: 只限于设置了 expire 的部分; 随机删除一部分 key。
- volatile-ttl: 只限于设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key。
  